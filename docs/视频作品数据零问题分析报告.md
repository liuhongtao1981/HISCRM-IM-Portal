# 视频/作品数据为零问题分析报告

**日期**: 2025-10-29
**问题**: DataManager 快照显示视频/作品 (Contents) 为 0
**状态**: ⚠️  待修复（需要实现作品抓取任务）

---

## 问题描述

### 现象

DataManager 数据快照显示：

- ✅ 会话 (Conversations): 28 条 - 正常
- ✅ 消息 (Messages): 42 条 - 已修复
- ✅ 评论 (Comments): 3 条 - 正常
- ❌ **视频/作品 (Contents): 0 条 - 异常**
- ⚠️  通知 (Notifications): 0 条 - 待确认

### 用户反馈

> 正常有 18~19 个作品，`https://creator.douyin.com/aweme/v1/creator/item/list?cursor=` 应该是整个 API 拦截回来的

---

## 根本原因分析

### 1. API 拦截器已注册 ✅

在 `packages/worker/src/platforms/douyin/platform.js:61` 中，作品 API 拦截器已正确注册：

```javascript
// 作品相关 API
manager.register('**/creator/item/list?**', onWorksListAPI);  // ✅ 已注册
```

回调函数 `onWorksListAPI` 也已正确实现（`crawl-contents.js:136`）：

```javascript
async function onWorksListAPI(body, route) {
  if (!body || !body.item_info_list) return;

  // ✅ 使用 DataManager（如果可用）
  if (globalContext.dataManager && body.item_info_list.length > 0) {
    try {
      const contents = globalContext.dataManager.batchUpsertContents(
        body.item_info_list,
        DataSource.API
      );
      logger.info(`✅ [API] 作品列表 -> DataManager: ${contents.length} 个作品`);
    } catch (error) {
      logger.error(`[API] 作品列表处理失败:`, error);
    }
  }
}
```

### 2. 关键问题：没有任务触发作品抓取 ❌

在 `packages/worker/src/handlers/monitor-task.js:250` 中，监控任务只执行**评论和私信**爬取：

```javascript
const [commentResult, dmResult] = await Promise.all([
  // 1. 爬取评论（spider2）
  this.platformInstance.crawlComments(this.account),

  // 2. 爬取私信（spider1）
  this.platformInstance.crawlDirectMessages(this.account)
]);

// ❌ 缺失：没有调用 crawlContents()
```

### 3. 完整的数据流分析

#### 评论数据流（✅ 正常工作）：
```
定时任务 → MonitorTask.run() → platform.crawlComments()
  → 打开评论页面
  → 触发 API: /comment/list
  → onCommentsListAPI() 回调
  → dataManager.batchUpsertComments()
  → 存储到 DataManager
  → 快照显示 3 条评论 ✅
```

#### 私信数据流（✅ 已修复）：
```
定时任务 → MonitorTask.run() → platform.crawlDirectMessages()
  → 打开私信页面
  → 触发 API: /creator/im/user_detail/
  → onConversationListAPI() 回调
  → dataManager.batchUpsertConversations()
  → DOM 提取消息
  → dataManager.batchUpsertMessages()
  → 存储到 DataManager
  → 快照显示 28 会话 + 42 消息 ✅
```

#### 作品数据流（❌ 完全缺失）：
```
定时任务 → MonitorTask.run() → ❌ 没有调用 platform.crawlContents()
  ❌ 从未打开作品列表页面
  ❌ API /creator/item/list 从未被触发
  ❌ onWorksListAPI() 回调从未执行
  ❌ dataManager.batchUpsertContents() 从未调用
  → 快照显示 0 条作品 ❌
```

---

## 证据验证

### 1. 日志文件验证

```bash
# crawl-contents.log 完全为空
$ cat packages/worker/logs/crawl-contents.log
(空文件)

# DataManager 日志中 contents 一直为 0
$ grep "contents" packages/worker/logs/douyin-data_acc-*.log
{"comments":3,"contents":0,"conversations":28,"messages":42,...}
```

### 2. 代码审查

```bash
# platform.js 中没有 crawlContents 方法实现
$ grep -n "async crawlContents" packages/worker/src/platforms/douyin/platform.js
(无匹配结果)

# monitor-task.js 中没有调用 crawlContents
$ grep -n "crawlContents" packages/worker/src/handlers/monitor-task.js
(无匹配结果)

# 但 crawl-contents.js 文件存在且有完整实现
$ ls -l packages/worker/src/platforms/douyin/crawl-contents.js
-rw-r--r-- 1 user user 15234 Oct 29 14:00 crawl-contents.js
```

### 3. 基类接口检查

在 `packages/worker/src/platforms/base/platform-base.js` 中：

```javascript
// ✅ 评论抓取接口
async crawlComments(account) {
  throw new Error('crawlComments must be implemented by subclass');
}

// ✅ 私信抓取接口
async crawlDirectMessages(account) {
  throw new Error('crawlDirectMessages must be implemented by subclass');
}

// ❌ 没有 crawlContents 接口！
// async crawlContents(account) { ... }
```

---

## 架构问题总结

### 当前架构

```
抖音平台监控任务
├─ crawlComments()      ✅ 已实现，定时调用
├─ crawlDirectMessages() ✅ 已实现，定时调用
└─ crawlContents()       ❌ 未实现，从未调用

文件存在但未集成：
└─ crawl-contents.js    ✅ 文件存在
   ├─ onWorksListAPI()  ✅ API 回调已实现
   ├─ crawlContents()   ✅ 爬取函数已实现
   └─ 但从未被调用      ❌ 未集成到监控循环
```

### 对比：消息数据修复前后

**修复前（消息问题）**：
- 问题：消息被爬取但未发送到 DataManager
- 原因：DOM 提取的消息未调用 `dataManager.batchUpsertMessages()`
- 修复：在爬取完成后添加调用

**当前（作品问题）**：
- 问题：作品 API 拦截器存在但从未被触发
- 原因：没有任务打开作品页面，API 永远不会被调用
- 需要：实现 `platform.crawlContents()` 并集成到监控循环

---

## 修复方案

### 方案 1: 集成现有的 crawl-contents.js（推荐）

#### 步骤 1: 在 platform-base.js 中添加接口

```javascript
// packages/worker/src/platforms/base/platform-base.js

/**
 * 爬取作品（需要子类实现）
 * @param {Object} account - 账户对象
 */
async crawlContents(account) {
  throw new Error('crawlContents must be implemented by subclass');
}
```

#### 步骤 2: 在 douyin/platform.js 中实现方法

```javascript
// packages/worker/src/platforms/douyin/platform.js

/**
 * 抓取作品列表
 * @param {Object} account - 账户对象
 * @returns {Promise<Object>} - { contents: Array, stats: Object }
 */
async crawlContents(account) {
  try {
    logger.info(`[crawlContents] Starting contents crawl for account ${account.id}`);

    if (!account.platform_user_id) {
      logger.error(`[crawlContents] Account ${account.id} missing platform_user_id`);
      return { contents: [], stats: {} };
    }

    // 第 1 步: 获取作品页面 Tab
    logger.debug(`[crawlContents] Step 1: Getting spider_content tab for account ${account.id}`);
    const { page, tabId } = await this.browserManager.getOrCreateTab(
      account.id,
      TabTag.SPIDER_CONTENT,
      true // closeAfterTask = true (任务完成后关闭)
    );

    if (!page) {
      throw new Error(`Failed to get spider_content tab for account ${account.id}`);
    }

    logger.info(`[crawlContents] Spider content tab retrieved successfully`);

    // 第 2 步: 创建或获取 DataManager
    let dataManager = null;
    try {
      dataManager = await this.getOrCreateDataManager(account.id);
      logger.info(`✅ [crawlContents] DataManager 可用，使用统一数据管理架构`);
    } catch (error) {
      logger.warn(`⚠️  [crawlContents] DataManager 创建失败，使用旧数据收集逻辑`);
    }

    // 第 3 步: 调用爬取函数
    logger.debug(`[crawlContents] Step 2: Running contents crawler`);
    const crawlResult = await crawlContents(page, account, {}, dataManager);

    const { contents, stats: crawlStats } = crawlResult;
    logger.info(`[crawlContents] Crawler completed: ${contents.length} contents`);

    // 第 4 步: 返回结果（DataManager 已自动处理存储）
    const stats = {
      contentsCount: contents.length,
      crawl_time: Math.floor(Date.now() / 1000),
      ...crawlStats,
    };

    logger.info(`[crawlContents] ✅ Contents crawl completed: ${contents.length} contents`);

    return {
      contents,
      stats
    };

  } catch (error) {
    logger.error(`[crawlContents] ❌ FATAL ERROR for account ${account.id}:`, error);
    logger.error(`[crawlContents] Error stack:`, error.stack);
    throw error;
  }
}
```

#### 步骤 3: 在 monitor-task.js 中添加作品抓取

```javascript
// packages/worker/src/handlers/monitor-task.js (line 250)

// ⭐ 改进: 并行执行评论、私信和作品爬取 (使用 Promise.all)
logger.info(`Starting parallel crawling: spider1 (DM), spider2 (Comments), spider3 (Contents)`);

const [commentResult, dmResult, contentResult] = await Promise.all([
  // 1. 爬取评论（spider2）
  (async () => {
    try {
      logger.info(`Spider2 (Comments) started for account ${this.account.id}`);
      const result = await this.platformInstance.crawlComments(this.account);
      logger.info(`Spider2 (Comments) completed for account ${this.account.id}`);
      return result;
    } catch (error) {
      logger.error(`Spider2 (Comments) failed: ${error.message}`);
      throw error;
    }
  })(),

  // 2. 爬取私信（spider1）
  (async () => {
    try {
      logger.info(`Spider1 (DM) started for account ${this.account.id}`);
      const result = await this.platformInstance.crawlDirectMessages(this.account);
      logger.info(`Spider1 (DM) completed for account ${this.account.id}`);
      return result;
    } catch (error) {
      logger.error(`Spider1 (DM) failed: ${error.message}`);
      throw error;
    }
  })(),

  // 3. ✅ 新增：爬取作品（spider3）
  (async () => {
    try {
      logger.info(`Spider3 (Contents) started for account ${this.account.id}`);
      const result = await this.platformInstance.crawlContents(this.account);
      logger.info(`Spider3 (Contents) completed for account ${this.account.id}`);
      return result;
    } catch (error) {
      logger.error(`Spider3 (Contents) failed: ${error.message}`);
      throw error;
    }
  })()
]);
```

#### 步骤 4: 更新 TabTag 枚举（如果需要）

```javascript
// packages/worker/src/browser/tab-manager.js

const TabTag = {
  LOGIN: 'login',
  SPIDER_COMMENT: 'spider_comment',  // Spider2: 评论
  SPIDER_DM: 'spider_dm',            // Spider1: 私信
  SPIDER_CONTENT: 'spider_content',  // Spider3: 作品（新增）
  REPLY_COMMENT: 'reply_comment',
  REPLY_DM: 'reply_dm',
};
```

---

## 预期效果

修复后，数据流将变为：

```
定时任务 → MonitorTask.run() → Promise.all([
  crawlComments(),      // ✅ 评论
  crawlDirectMessages(),// ✅ 私信
  crawlContents()       // ✅ 作品（新增）
])

作品数据流：
  → 打开作品列表页面 (https://creator.douyin.com/creator-micro/content/manage)
  → 触发 API: /creator/item/list?cursor=...
  → onWorksListAPI() 回调执行
  → dataManager.batchUpsertContents(body.item_info_list, DataSource.API)
  → 存储到 DataManager
  → 快照显示 18-19 条作品 ✅
```

### 日志示例

修复后应该看到类似日志：

```
[Spider3 (Contents)] Started for account acc-xxx
✅ [API] 作品列表 -> DataManager: 10 个作品
✅ [API] 作品列表 -> DataManager: 9 个作品
[crawlContents] ✅ Contents crawl completed: 19 contents
[Spider3 (Contents)] Completed for account acc-xxx
```

### DataManager 快照

```json
{
  "comments": 3,
  "conversations": 28,
  "messages": 42,
  "contents": 19,  // ✅ 从 0 变为 19
  "notifications": 0
}
```

---

## 额外考虑

### 1. 性能影响

并行执行三个爬取任务（评论、私信、作品）可能增加：
- **浏览器标签页数量**：从 2 个增加到 3 个
- **内存使用**：每个标签页约 100-200MB
- **CPU 使用**：并行爬取会增加 CPU 负载

**建议**：
- 监控内存使用，确保不超过系统限制
- 如果性能不足，可以改为串行执行（依次执行三个任务）

### 2. 错误处理

作品抓取失败不应影响评论和私信：

```javascript
// 使用 Promise.allSettled 代替 Promise.all
const [commentResult, dmResult, contentResult] = await Promise.allSettled([
  crawlComments(),
  crawlDirectMessages(),
  crawlContents()  // 失败也不影响其他任务
]);

// 处理每个结果
if (commentResult.status === 'fulfilled') { /* ... */ }
if (dmResult.status === 'fulfilled') { /* ... */ }
if (contentResult.status === 'fulfilled') { /* ... */ }
```

### 3. 频率控制

作品更新频率可能低于评论/私信，可以考虑：

```javascript
// 每5次监控任务执行1次作品抓取
if (this.executionCount % 5 === 0) {
  contentResult = await this.platformInstance.crawlContents(this.account);
}
```

---

## 相关文档

- [消息数据零问题修复报告](./消息数据零问题修复报告.md) - 类似问题的修复案例
- [05-DOUYIN-平台实现技术细节](./05-DOUYIN-平台实现技术细节.md)
- [06-WORKER-爬虫调试指南](./06-WORKER-爬虫调试指南.md)
- [DataManager 数据快照功能完整指南](./DataManager数据快照功能完整指南.md)

---

## 总结

**问题根源**：作品抓取功能的代码已实现，但从未被集成到监控任务循环中。

**修复思路**：
1. ✅ API 拦截器已注册 → 无需修改
2. ✅ 爬取函数已实现 (crawl-contents.js) → 无需修改
3. ❌ 基类接口缺失 → 需要添加 `crawlContents()` 接口
4. ❌ 平台未实现 → 需要在 `douyin/platform.js` 中实现
5. ❌ 监控任务未调用 → 需要在 `monitor-task.js` 中添加调用

**修复优先级**：高
**预计工作量**：2-3 小时（包括测试）

---

**维护者**: Claude Code
**版本**: v1.0
**最后更新**: 2025-10-29
