# 评论讨论数据未入库问题诊断报告

**日期**: 2025-10-25
**问题**: 评论(comments)、讨论(discussions)、作品(douyin_videos) 表数据为 0
**状态**: 🔍 **根本原因已定位**

---

## 📊 当前数据库状态

```
✅ 私信 (direct_messages): 15 条
✅ 会话 (conversations): 3 个
❌ 评论 (comments): 0 条
❌ 讨论 (discussions): 0 条
❌ 作品 (douyin_videos): 0 条
```

---

## 🔍 问题分析时间线

### 执行 #1: 01:03:36 - 01:04:03 (27秒)

**爬虫执行**:
```
01:03:36.393 - Spider2 (Comments) started
01:04:03.731 - Processing 3 comment APIs, 1 discussion APIs ✅
01:04:03.731 - Total: 4 comments from 1 videos ✅
01:04:03.732 - Total: 3 discussions for 1 comments ✅
```

**发送尝试**:
```
01:04:03.760 - Spider2 failed: Cannot read properties of undefined (reading 'socket') ❌
```

**结论**: ✅ **成功抓取** 4评论+3讨论，❌ **发送失败**（workerBridge未定义）

---

### 执行 #2: 01:04:28 - 01:04:41 (12秒)

**爬虫执行**:
```
01:04:28.928 - Spider2 started
01:04:41.117 - Processing 0 comment APIs, 0 discussion APIs ❌
01:04:41.117 - Total: 0 comments from 0 videos
01:04:41.118 - Spider2 completed
```

**结论**: ❌ **未抓取到数据**（API拦截器未捕获）

---

### 执行 #3: 01:05:23 - 01:05:51 (28秒)

**爬虫执行**:
```
01:05:23.636 - Spider2 started
01:05:51.482 - Processing 3 comment APIs, 1 discussion APIs ✅
01:05:51.485 - Total: 4 comments from 1 videos ✅
01:05:51.485 - Total: 3 discussions for 1 comments ✅
```

**发送尝试**:
```
01:05:51.487 - Spider2 failed: Cannot read properties of undefined (reading 'socket') ❌
```

**结论**: ✅ **成功抓取** 4评论+3讨论，❌ **发送失败**（workerBridge未定义）

---

### 执行 #4: 01:06:13 - 01:06:25 (12秒)

**爬虫执行**:
```
01:06:13.327 - Spider2 started
01:06:25.433 - Processing 0 comment APIs, 0 discussion APIs ❌
01:06:25.433 - Total: 0 comments from 0 videos
01:06:25.436 - Spider2 completed ✅
```

**平台日志**:
```
01:06:25.434 - Crawler completed: 0 comments, 0 discussions, 0 works
01:06:25.435 - No new comments to send (all 0 comments are duplicates)
```

**结论**: ❌ **未抓取到数据**，但 workerBridge 错误已修复

---

### 执行 #5: 01:07:15 - 01:07:28 (13秒)

**爬虫执行**:
```
01:07:15.137 - Spider2 started
01:07:28.219 - Processing 0 comment APIs, 0 discussion APIs ❌
01:07:28.219 - Total: 0 comments from 0 videos
```

**结论**: ❌ **持续未抓取到数据**

---

### 执行 #6: 01:08:21 - 01:08:22 (1秒)

**爬虫执行**:
```
01:08:21.838 - Spider2 started
01:08:22.618 - Spider2 failed: page.waitForTimeout: Target page has been closed ❌
```

**结论**: ❌ **浏览器崩溃**，爬虫失败

---

## 🎯 根本原因分析

### 原因 1: workerBridge 命名不一致 (已修复)

**问题**:
```javascript
// platform.js line 721
this.workerBridge.socket.emit(...)  // ❌ workerBridge 未定义

// 应该是:
this.bridge.socket.emit(...)  // ✅ bridge 是正确的属性名
```

**影响**:
- 第 #1、#3 次执行成功抓取了数据（4评论+3讨论）
- 但发送到 Master 时失败
- 数据丢失，未入库

**修复**:
- ✅ 已修改 `platform.js` line 721, 760
- 将 `this.workerBridge.socket` 改为 `this.bridge.socket`

---

### 原因 2: API 拦截器不稳定

**现象**:
- 第 #1、#3 次执行: 成功捕获 API 数据 ✅
- 第 #2、#4、#5 次执行: 未捕获任何 API 数据 ❌

**可能原因**:

#### 2.1 页面缓存机制
```
抖音评论管理页面使用了数据缓存:
- 第一次访问: 触发 API 请求，数据从服务器加载
- 后续访问: 直接使用缓存数据，不触发 API
```

**证据**:
- 执行时长对比：
  - 有数据的执行: 27-28秒（API请求时间）
  - 无数据的执行: 12-13秒（直接使用缓存）

#### 2.2 API 拦截器注册时机
```javascript
// crawl-comments.js
page.on('response', async (response) => {
  // API 拦截逻辑
});
```

**问题**:
- 如果页面已经加载完成，再注册拦截器就捕获不到已完成的请求
- 需要在页面加载**之前**注册拦截器

#### 2.3 页面状态复用
```
Spider2 使用持久 tab（persistent=true）:
- 优点: 减少浏览器资源占用
- 缺点: 页面状态（包括缓存）会保留
```

---

### 原因 3: 浏览器持续崩溃

**证据**:
```
01:08:22.605 - crawlDirectMessages failed: Target page has been closed
01:08:22.618 - crawlComments failed: Target page has been closed
```

**可能原因**:

1. **用户手动关闭浏览器窗口**
   - `HEADLESS=false` 导致浏览器可见
   - 用户可能误操作关闭了窗口

2. **系统资源不足**
   - 浏览器内存占用过高
   - 系统自动 kill 进程

3. **浏览器超时**
   - Playwright 默认超时设置
   - 长时间无操作导致断开

---

## 🛠️ 解决方案

### 方案 1: 修复 workerBridge 错误 ✅ (已完成)

**状态**: ✅ **已修复**

**修改文件**:
- `packages/worker/src/platforms/douyin/platform.js` (Line 721, 760)

**测试方法**:
- 重启 Worker
- 等待下一次爬虫执行
- 检查 Master 日志是否收到评论/讨论数据

---

### 方案 2: 强制刷新页面清除缓存

**目标**: 确保每次执行都触发 API 请求

**实现**:
```javascript
// crawl-comments.js - 在导航前添加
await page.goto('about:blank');  // 清空页面
await page.goto(commentManageUrl, {
  waitUntil: 'networkidle',
  timeout: 60000
});
```

**优点**:
- 强制重新加载页面和数据
- 确保 API 拦截器能捕获请求

**缺点**:
- 增加加载时间
- 可能触发反爬检测

---

### 方案 3: 在导航前注册 API 拦截器

**目标**: 确保拦截器在页面加载之前就绪

**实现**:
```javascript
// crawl-comments.js - 调整顺序

// ✅ 先注册拦截器
const apiResponses = { comments: [], discussions: [] };
page.on('response', async (response) => {
  // 拦截逻辑
});

// ✅ 再导航页面
await navigateToCommentManage(page);
```

**当前代码顺序**: 正确 ✅（已经是这个顺序）

---

### 方案 4: 使用 forceNew=true 创建新 Tab

**目标**: 每次执行使用全新的 tab，避免缓存影响

**实现**:
```javascript
// platform.js line 654
const { page } = await this.browserManager.tabManager.getPageForTask(account.id, {
  tag: TabTag.SPIDER_COMMENT,
  persistent: false,    // 改为 false，每次用完即关闭
  shareable: false,
  forceNew: true        // 改为 true，强制创建新 tab
});
```

**优点**:
- 完全避免缓存问题
- 每次执行都是干净的环境

**缺点**:
- 增加浏览器资源占用
- 每次都需要加载页面

---

### 方案 5: 修复浏览器崩溃问题

**选项 A: 启用 HEADLESS 模式**
```bash
# packages/worker/.env
HEADLESS=true  # 改为 true，避免用户误操作
```

**选项 B: 增加浏览器稳定性监控**
```javascript
// browser-manager-v2.js - 添加定期检查
setInterval(async () => {
  for (const [accountId, browser] of this.browsers.entries()) {
    if (!browser.isConnected()) {
      logger.warn(`Browser disconnected for ${accountId}, recreating...`);
      await this.createContextForAccount(accountId);
    }
  }
}, 30000);  // 每30秒检查一次
```

---

## 📋 推荐修复顺序

### 优先级 P0: 立即执行

1. ✅ **修复 workerBridge 错误** - 已完成
2. 🔄 **重启 Worker 测试** - 验证修复效果
3. 📊 **检查数据是否入库** - 等待下一次爬虫执行

### 优先级 P1: 短期优化

4. 🔧 **添加页面强制刷新**
   - 在 `navigateToCommentManage()` 前添加 `goto('about:blank')`
   - 测试是否解决 API 捕获问题

5. 🔧 **改为 forceNew=true**
   - 修改 `getPageForTask` 参数
   - 测试数据稳定性

### 优先级 P2: 长期改进

6. 🔧 **启用 HEADLESS 模式**
   - 避免用户误操作
   - 减少浏览器资源占用

7. 🔧 **添加浏览器健康检查**
   - 定期检测浏览器连接状态
   - 自动重启崩溃的浏览器

---

## 📝 测试计划

### 测试 1: 验证 workerBridge 修复

**步骤**:
1. 重启 Worker
2. 等待 20-30 秒（一个爬虫周期）
3. 检查 Master 日志: `tail -50 packages/master/logs/message-receiver.log`
4. 查找 comment 或 discussion 类型的消息

**期望结果**:
```
Message detected from worker: comment
Message detected from worker: discussion
```

---

### 测试 2: 验证数据入库

**步骤**:
```bash
node tests/检查所有爬虫数据.js
```

**期望结果**:
```
✅ 评论 (comments): > 0 条
✅ 讨论 (discussions): > 0 条
```

---

### 测试 3: 验证浏览器稳定性

**步骤**:
1. 监控 Worker 日志 30 分钟
2. 观察是否有 "Target page has been closed" 错误

**期望结果**:
- 0 次浏览器崩溃错误

---

## 🎯 成功标准

1. ✅ **评论数据入库**: comments 表 > 0 条
2. ✅ **讨论数据入库**: discussions 表 > 0 条
3. ✅ **数据稳定性**: 连续 5 次爬虫执行都能抓到数据
4. ✅ **浏览器稳定**: 30 分钟内 0 次崩溃

---

**文档版本**: v1.0
**最后更新**: 2025-10-25 01:15
**下一步**: 等待 Worker 重启后验证修复效果
