# 并发爬虫冲突问题 - 最终诊断

## 时间: 2025-11-05 10:10

## 用户发现的关键线索

用户问："会不会是爬虫执行过程中，第二次爬虫请求，中断了第一次的"

**这个怀疑是100%正确的！**

## 根本原因

### 现象

```
09:54:02.255 - 评论爬虫开始
09:54:02.256 - 私信爬虫开始（并发执行）
09:55:09.111 - 评论爬虫完成（正常）
（之后）     - 私信爬虫永远没有完成（卡住）
```

### 架构设计

系统使用了**正确的并发隔离设计**：

1. ✅ **独立的 Tab**:
   - `spider_comment` (Tab 2) - 评论爬虫
   - `spider_dm` (Tab 1) - 私信爬虫

2. ✅ **独立的 API 拦截器**:
   - `acc-xxx_spider_comment` - 评论的 API Manager
   - `acc-xxx_spider_dm` - 私信的 API Manager

3. ✅ **独立的 Page 对象**:
   - 评论爬虫和私信爬虫使用不同的浏览器标签页

### 但有一个致命缺陷！

`crawl-direct-messages-v2.js` Line 18-32:

```javascript
// ==================== 全局状态（用于 API 回调）====================
const globalContext = {
  dataManager: null,  // ← 全局共享！
  accountId: null,    // ← 全局共享！
};

const apiData = {
  init: [],           // ← 全局共享！
  conversations: [],  // ← 全局共享！
  history: [],        // ← 全局共享！
  cache: {
    init: new Set(),
    conversations: new Set(),
    history: new Set()
  }
};
```

**问题**: `globalContext` 和 `apiData` 是**模块级全局变量**，所有并发的爬虫实例共享！

### 冲突场景

#### 时间线

```
T=0ms    评论爬虫 crawlCommentsV2() 开始
         → globalContext.dataManager = commentDataManager ✅
         → globalContext.accountId = 'acc-xxx' ✅

T=1ms    私信爬虫 crawlDirectMessagesV2() 开始
         → globalContext.dataManager = dmDataManager ❌ 覆盖了！
         → globalContext.accountId = 'acc-xxx' ❌ 覆盖了！
         → apiData.init = [] ❌ 清空了评论的数据！
         → apiData.conversations = [] ❌ 清空了！

T=500ms  抖音返回评论 API 响应
         → spider_comment 的 API 拦截器触发 ✅
         → 调用 onCommentsListAPI(body)
         → 使用 globalContext.dataManager ❌ 但现在是 dmDataManager！
         → 评论数据被写入了私信的 DataManager！

T=1000ms 抖音返回会话列表 API 响应
         → spider_dm 的 API 拦截器触发 ✅
         → 调用 onConversationListAPI(body)
         → 使用 globalContext.dataManager ✅ 正确的 dmDataManager
         → 但同时也包含了评论的数据！❌

T=60s    评论爬虫完成
         → globalContext.dataManager = null ❌ 清空了私信爬虫的！
         → 私信爬虫后续的 API 回调全部失败！
```

#### 数据流混乱

```
评论 API 数据 → spider_comment 拦截器 → onCommentsListAPI
               ↓
               使用 globalContext.dataManager
               ↓
               但此时是 dmDataManager！
               ↓
               评论数据写入了私信的 DataManager ❌

私信 API 数据 → spider_dm 拦截器 → onConversationListAPI
               ↓
               使用 globalContext.dataManager
               ↓
               正确的 dmDataManager ✅
               ↓
               但包含了混入的评论数据 ❌
```

### 为什么私信爬虫会卡住或返回0消息

1. **评论爬虫完成时** (Line 314-318):
   ```javascript
   } finally {
     globalContext.dataManager = null;  ← 清空！
     globalContext.accountId = null;
   }
   ```

2. **此时私信爬虫可能还在运行**，后续的 API 回调会失败：
   ```javascript
   if (globalContext.dataManager && body.data.messages.length > 0) {
     // globalContext.dataManager 已经是 null！
     // 数据无法写入 DataManager
   }
   ```

3. **apiData 被清空**:
   ```javascript
   // 私信爬虫启动时 (Line 196-202)
   apiData.init = [];          // ← 清空了评论爬虫的数据！
   apiData.conversations = [];
   apiData.history = [];
   ```

4. **最终结果**:
   - 私信爬虫的 `extractConversationsList` 使用 `apiData.conversations`
   - 但 `apiData.conversations` 可能在中途被清空
   - 或者包含错误的评论数据
   - 导致提取失败，返回 0 条消息

## 为什么之前能正常工作

之前正常是因为：
1. 评论爬虫和私信爬虫**不是并发**执行
2. 或者它们的执行时间**没有重叠**
3. Worker 重启后，调度时间可能发生变化，导致并发执行

从日志看：
- 09:54:02.255 - 评论开始
- 09:54:02.256 - 私信开始（仅隔1毫秒！）

这种极度紧密的并发几乎必然导致冲突。

## 解决方案

### 方案1: 禁用并发（最快）

修改 `monitor-task.js` Line 250，从 `Promise.all` 改为顺序执行：

```javascript
// 方案1: 禁用并发，顺序执行
const commentResult = await (async () => {
  try {
    logger.info(`Spider2 (Comments) started for account ${this.account.id}`);
    const result = await this.platformInstance.crawlComments(this.account.id);
    logger.info(`Spider2 (Comments) completed for account ${this.account.id}`);
    return result;
  } catch (error) {
    logger.error(`Spider2 (Comments) failed: ${error.message}`);
    throw error;
  }
})();

const dmResult = await (async () => {
  try {
    logger.info(`Spider1 (DM) started for account ${this.account.id}`);
    const result = await this.platformInstance.crawlDirectMessages(this.account.id);
    logger.info(`Spider1 (DM) completed for account ${this.account.id}`);
    return result;
  } catch (error) {
    logger.error(`Spider1 (DM) failed: ${error.message}`);
    throw error;
  }
})();
```

### 方案2: 为每个爬虫创建独立的 apiData（推荐）

修改 `crawl-direct-messages-v2.js`，将 `apiData` 从全局变量改为函数参数：

```javascript
// 删除全局 apiData
// const apiData = { ... };  ← 删除

// 修改函数签名，接收 apiData 作为参数
async function crawlDirectMessagesV2(page, account, dataManager = null) {
  logger.info(`[Phase 8] Starting enhanced private message crawl for account ${account.id}`);

  // ✅ 创建本次爬虫专用的 apiData
  const apiData = {
    init: [],
    conversations: [],
    history: [],
    cache: {
      init: new Set(),
      conversations: new Set(),
      history: new Set()
    }
  };

  // ✅ 设置全局上下文，并将 apiData 也存储到 globalContext
  if (dataManager) {
    globalContext.dataManager = dataManager;
    globalContext.accountId = account.id;
    globalContext.apiData = apiData;  // ← 新增
    logger.info(`✅ [DataManager] 已启用统一数据管理架构`);
  }

  try {
    // 不再清空 apiData（因为是新创建的）
    // apiData.init = [];  ← 删除

    // ... 其余逻辑保持不变
  } finally {
    // ✅ 只清理本次爬虫的 globalContext
    if (globalContext.accountId === account.id) {
      globalContext.dataManager = null;
      globalContext.accountId = null;
      globalContext.apiData = null;
    }
  }
}
```

然后修改 API 回调函数，使用 `globalContext.apiData`：

```javascript
async function onConversationListAPI(body) {
  if (!body || !body.user_list) return;

  // ✅ 使用 DataManager
  if (globalContext.dataManager && body.user_list.length > 0) {
    // ... DataManager 逻辑
  }

  // ✅ 使用当前爬虫的 apiData
  if (globalContext.apiData) {
    globalContext.apiData.conversations.push(body);
  }

  logger.debug(`收集到会话列表: ${body.user_list.length} 个会话`);
}
```

### 方案3: 使用账户ID区分（推荐）

在 `globalContext` 中使用 Map 而不是单个值：

```javascript
const globalContext = {
  dataManagers: new Map(),  // accountId → dataManager
  apiDataMap: new Map(),    // accountId → apiData
};

// 设置
globalContext.dataManagers.set(account.id, dataManager);
globalContext.apiDataMap.set(account.id, apiData);

// 获取
const dm = globalContext.dataManagers.get(accountId);
const apiData = globalContext.apiDataMap.get(accountId);

// 清理
globalContext.dataManagers.delete(account.id);
globalContext.apiDataMap.delete(account.id);
```

## 建议

**立即采用方案1**（禁用并发），因为：
1. ✅ 最快，只需修改 1 个文件
2. ✅ 风险最低
3. ✅ 不影响其他逻辑
4. ✅ 性能损失可接受（评论+私信总共约10分钟）

**未来采用方案3**（Map存储），因为：
1. ✅ 支持真正的并发
2. ✅ 架构更清晰
3. ✅ 可扩展性好

## 相关文件

- `packages/worker/src/handlers/monitor-task.js` Line 250 - 并发执行逻辑
- `packages/worker/src/platforms/douyin/crawl-direct-messages-v2.js` Line 18-32 - 全局状态
- `packages/worker/src/platforms/base/platform-base.js` - getPageWithAPI 方法
