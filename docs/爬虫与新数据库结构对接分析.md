# 爬虫系统与新数据库结构对接分析

> 分析时间: 2025-10-24
> 数据库版本: v1.0 (2025-10-23)
> 分析范围: Worker 爬虫 → Master 数据库存储

---

## 一、新增数据表概览

### 1.1 核心 IM 相关表 (新增/扩展)

| 表名 | 状态 | 列数 | DAO 状态 | Worker 支持 |
|-----|------|------|---------|-------------|
| `works` | ✅ 新增 | 21 列 | ❌ 缺失 | ❌ 无对接 |
| `discussions` | ✅ 新增 | 17 列 | ❌ 缺失 | ❌ 无对接 |
| `conversations` | ✅ 扩展 | 16 列 | ✅ 已实现 | ✅ 已对接 |
| `direct_messages` | ✅ 扩展 | 26 列 | ✅ 已实现 | ✅ 已对接 |
| `comments` | ✅ 扩展 | 16 列 | ✅ 已实现 | ✅ 已对接 |
| `douyin_videos` | ⚠️ 过时 | 20 列 | ✅ 已实现 | ⚠️ 待迁移 |

### 1.2 新增字段详情

#### `works` 表 (作品管理 - 通用表)
```sql
CREATE TABLE works (
  id TEXT PRIMARY KEY,
  account_id TEXT NOT NULL,
  platform TEXT NOT NULL,
  platform_work_id TEXT NOT NULL,
  platform_user_id TEXT,

  -- 作品类型和信息
  work_type TEXT NOT NULL CHECK(work_type IN ('video', 'article', 'image', 'audio', 'text')),
  title TEXT,
  description TEXT,
  cover TEXT,
  url TEXT,
  publish_time INTEGER,

  -- 统计信息
  total_comment_count INTEGER DEFAULT 0,
  new_comment_count INTEGER DEFAULT 0,
  like_count INTEGER DEFAULT 0,
  share_count INTEGER DEFAULT 0,
  view_count INTEGER DEFAULT 0,

  -- 爬取状态
  last_crawl_time INTEGER,
  crawl_status TEXT DEFAULT 'pending',
  crawl_error TEXT,

  -- 标记
  is_new BOOLEAN DEFAULT 1,
  push_count INTEGER DEFAULT 0,

  -- 时间戳
  created_at INTEGER NOT NULL,
  updated_at INTEGER NOT NULL,

  UNIQUE(account_id, platform, platform_work_id),
  FOREIGN KEY (account_id) REFERENCES accounts(id) ON DELETE CASCADE
);
```

**用途**: 替代 `douyin_videos` 表，支持多平台多类型作品 (视频/图文/音频等)

---

#### `discussions` 表 (评论区讨论)
```sql
CREATE TABLE discussions (
  id TEXT PRIMARY KEY,
  account_id TEXT NOT NULL,
  platform TEXT NOT NULL,
  platform_user_id TEXT,
  platform_discussion_id TEXT,

  -- 关联到父评论
  parent_comment_id TEXT NOT NULL,

  -- 讨论内容
  content TEXT NOT NULL,
  author_name TEXT,
  author_id TEXT,

  -- 关联作品信息
  work_id TEXT,
  post_id TEXT,
  post_title TEXT,

  -- 状态
  is_read BOOLEAN DEFAULT 0,
  is_new BOOLEAN DEFAULT 1,
  push_count INTEGER DEFAULT 0,
  author_avatar TEXT,
  like_count INTEGER DEFAULT 0,

  -- 时间戳
  detected_at INTEGER NOT NULL,
  created_at INTEGER NOT NULL,

  UNIQUE(account_id, platform_user_id, platform_discussion_id),
  FOREIGN KEY (account_id) REFERENCES accounts(id) ON DELETE CASCADE,
  FOREIGN KEY (parent_comment_id) REFERENCES comments(id) ON DELETE CASCADE,
  FOREIGN KEY (work_id) REFERENCES works(id) ON DELETE SET NULL
);
```

**用途**: 处理评论下的回复和讨论（二级评论/三级评论）

---

#### `conversations` 表 (扩展字段)
新增字段:
- `is_pinned BOOLEAN` - 是否置顶
- `is_muted BOOLEAN` - 是否静音
- `last_message_type TEXT` - 最后消息类型 (text/image/video/audio)
- `status TEXT` - 会话状态 (active/archived/blocked)

---

#### `direct_messages` 表 (扩展字段)
新增字段:
- `sender_name TEXT` - 发送者名称
- `status TEXT` - 消息状态 (sent/delivered/read/failed)
- `reply_to_message_id TEXT` - 回复的消息 ID
- `media_url TEXT` - 媒体 URL
- `media_thumbnail TEXT` - 媒体缩略图
- `file_size INTEGER` - 文件大小
- `file_name TEXT` - 文件名称
- `duration INTEGER` - 音视频时长
- `is_deleted BOOLEAN` - 是否已删除
- `is_recalled BOOLEAN` - 是否已撤回
- `recalled_at INTEGER` - 撤回时间

---

#### `comments` 表 (扩展字段)
新增字段:
- `author_avatar TEXT` - 作者头像
- `like_count INTEGER` - 点赞数
- `reply_count INTEGER` - 回复数

---

## 二、现有爬虫实现状态

### 2.1 抖音平台爬虫

#### ✅ 已实现
- **私信爬虫**: `crawl-direct-messages-v2.js`
  - 支持虚拟列表完整历史抓取
  - API 拦截获取完整消息 ID
  - 会话表数据存储
  - 消息-会话关联

- **评论爬虫**: 基础实现 (需扩展)
  - 当前仅抓取一级评论
  - 存储到 `comments` 表

#### ❌ 未实现
- **作品爬虫**:
  - 当前使用 `douyin_videos` 表 (仅视频)
  - 未迁移到通用 `works` 表
  - 不支持图文/音频等其他类型

- **讨论爬虫**:
  - 未抓取评论区的二级/三级回复
  - 未存储到 `discussions` 表

### 2.2 Worker → Master 数据上报

#### ✅ 已实现上报
```javascript
// message-reporter.js
reportComments(accountId, comments)        // ✅ 支持
reportDirectMessages(accountId, messages)  // ✅ 支持
reportConversations(accountId, conversations) // ✅ 支持 (仅日志)
```

#### ❌ 未实现上报
```javascript
reportWorks(accountId, works)              // ❌ 缺失
reportDiscussions(accountId, discussions)  // ❌ 缺失
```

### 2.3 Master 数据处理

#### ✅ 已实现 DAO
- `CommentsDAO` → `comments` 表
- `DirectMessagesDAO` → `direct_messages` 表
- `ConversationsDAO` → `conversations` 表
- `DouyinVideoDAO` → `douyin_videos` 表 (旧表)

#### ❌ 缺失 DAO
- ❌ `WorksDAO` → `works` 表
- ❌ `DiscussionsDAO` → `discussions` 表

---

## 三、待开发功能清单

### 3.1 核心开发任务 (高优先级)

#### 📋 任务 1: 实现 `WorksDAO`
**文件**: `packages/master/src/database/works-dao.js`

**需要实现的方法**:
```javascript
class WorksDAO {
  // 基础 CRUD
  insert(work)                          // 插入单个作品
  bulkInsert(works)                     // 批量插入作品
  update(id, updates)                   // 更新作品信息
  delete(id)                            // 删除作品

  // 查询
  findById(id)                          // 根据 ID 查询
  findByPlatformWorkId(accountId, platform, platformWorkId) // 唯一约束查询
  findByAccount(accountId, options)     // 按账户查询 (分页/过滤)
  findByPlatform(platform, options)     // 按平台查询
  findByWorkType(workType, options)     // 按作品类型查询

  // 统计
  getWorkStats(accountId)               // 获取作品统计
  updateCommentCount(workId, count)     // 更新评论数
  updateViewCount(workId, count)        // 更新浏览数

  // 爬取状态
  updateCrawlStatus(workId, status, error)  // 更新爬取状态
  getPendingWorks(limit)                // 获取待爬取作品
}
```

**参考文件**: `douyin-video-dao.js`, `comments-dao.js`

---

#### 📋 任务 2: 实现 `DiscussionsDAO`
**文件**: `packages/master/src/database/discussions-dao.js`

**需要实现的方法**:
```javascript
class DiscussionsDAO {
  // 基础 CRUD
  insert(discussion)                    // 插入单个讨论
  bulkInsert(discussions)               // 批量插入讨论
  update(id, updates)                   // 更新讨论
  delete(id)                            // 删除讨论

  // 查询
  findById(id)                          // 根据 ID 查询
  findByParentComment(parentCommentId)  // 查询某评论下的所有讨论
  findByWork(workId, options)           // 查询某作品下的所有讨论
  findByAccount(accountId, options)     // 按账户查询

  // 标记状态
  markAsRead(id)                        // 标记为已读
  markAsNotNew(id)                      // 标记为非新消息

  // 统计
  getUnreadCount(accountId)             // 获取未读讨论数
  getDiscussionStats(accountId)         // 获取讨论统计
}
```

**参考文件**: `comments-dao.js`, `messages-dao.js`

---

#### 📋 任务 3: Worker 实现作品爬虫
**文件**: `packages/worker/src/platforms/douyin/crawl-works.js`

**功能需求**:
1. 访问用户主页或创作者中心
2. 抓取所有作品列表 (视频/图文等)
3. 提取作品详情:
   - 作品类型 (video/image/article)
   - 标题、封面、描述
   - 统计数据 (点赞/评论/分享/播放)
   - 发布时间
4. 上报到 Master

**实现步骤**:
```javascript
async function crawlWorks(page, account) {
  // 1. 导航到用户主页或创作者中心
  await page.goto(`https://creator.douyin.com/...`);

  // 2. 提取作品列表 (虚拟列表滚动加载)
  const works = await extractWorksFromVirtualList(page, account);

  // 3. 对每个作品获取详细信息
  for (const work of works) {
    const details = await getWorkDetails(page, work);
    work.details = details;
  }

  // 4. 返回标准化数据
  return works.map(work => ({
    id: uuidv4(),
    account_id: account.id,
    platform: 'douyin',
    platform_work_id: work.aweme_id,
    platform_user_id: account.platform_user_id,
    work_type: detectWorkType(work),
    title: work.title,
    description: work.description,
    cover: work.cover_url,
    url: work.share_url,
    publish_time: work.create_time,
    total_comment_count: work.statistics.comment_count,
    new_comment_count: 0,
    like_count: work.statistics.digg_count,
    share_count: work.statistics.share_count,
    view_count: work.statistics.play_count,
    last_crawl_time: Math.floor(Date.now() / 1000),
    crawl_status: 'success',
    is_new: true,
    push_count: 0,
    created_at: Math.floor(Date.now() / 1000),
    updated_at: Math.floor(Date.now() / 1000),
  }));
}
```

---

#### 📋 任务 4: Worker 实现讨论爬虫
**文件**: `packages/worker/src/platforms/douyin/crawl-discussions.js`

**功能需求**:
1. 在已爬取的评论基础上
2. 展开每个评论的回复列表
3. 抓取二级/三级回复
4. 关联到父评论和作品
5. 上报到 Master

**实现步骤**:
```javascript
async function crawlDiscussions(page, account, parentComment) {
  // 1. 点击展开评论的回复
  await expandCommentReplies(page, parentComment);

  // 2. 滚动加载所有回复
  const replies = await loadAllReplies(page, parentComment);

  // 3. 返回标准化数据
  return replies.map(reply => ({
    id: uuidv4(),
    account_id: account.id,
    platform: 'douyin',
    platform_user_id: account.platform_user_id,
    platform_discussion_id: reply.cid,
    parent_comment_id: parentComment.id,
    content: reply.text,
    author_name: reply.user.nickname,
    author_id: reply.user.uid,
    author_avatar: reply.user.avatar_url,
    work_id: parentComment.work_id,
    post_id: parentComment.post_id,
    post_title: parentComment.post_title,
    like_count: reply.digg_count,
    is_read: false,
    is_new: true,
    push_count: 0,
    detected_at: Math.floor(Date.now() / 1000),
    created_at: reply.create_time,
  }));
}
```

---

#### 📋 任务 5: Worker 消息上报器扩展
**文件**: `packages/worker/src/communication/message-reporter.js`

**新增方法**:
```javascript
class MessageReporter {
  /**
   * 上报作品
   */
  reportWorks(accountId, works) {
    if (!Array.isArray(works) || works.length === 0) return;

    logger.info(`Reporting ${works.length} works for account ${accountId}`);

    // 方式 1: 单条上报 (类似 comments)
    for (const work of works) {
      this.reportMessage(accountId, 'work', work);
    }

    // 方式 2: 批量上报 (性能更好)
    const message = createMessage(WORKER_BULK_INSERT_WORKS, {
      account_id: accountId,
      works: works,
    });
    this.socketClient.sendMessage(message);
  }

  /**
   * 上报讨论
   */
  reportDiscussions(accountId, discussions) {
    if (!Array.isArray(discussions) || discussions.length === 0) return;

    logger.info(`Reporting ${discussions.length} discussions for account ${accountId}`);

    for (const discussion of discussions) {
      this.reportMessage(accountId, 'discussion', discussion);
    }
  }

  /**
   * 批量上报所有数据
   */
  reportAll(accountId, detectedMessages) {
    if (detectedMessages.comments?.length > 0) {
      this.reportComments(accountId, detectedMessages.comments);
    }

    if (detectedMessages.directMessages?.length > 0) {
      this.reportDirectMessages(accountId, detectedMessages.directMessages);
    }

    if (detectedMessages.conversations?.length > 0) {
      this.reportConversations(accountId, detectedMessages.conversations);
    }

    // ✨ 新增
    if (detectedMessages.works?.length > 0) {
      this.reportWorks(accountId, detectedMessages.works);
    }

    // ✨ 新增
    if (detectedMessages.discussions?.length > 0) {
      this.reportDiscussions(accountId, detectedMessages.discussions);
    }
  }
}
```

---

#### 📋 任务 6: Master 消息接收器扩展
**文件**: `packages/master/src/communication/message-receiver.js`

**新增处理器**:
```javascript
const WorksDAO = require('../database/works-dao');
const DiscussionsDAO = require('../database/discussions-dao');

class MessageReceiver {
  constructor(db) {
    this.worksDAO = new WorksDAO(db);
    this.discussionsDAO = new DiscussionsDAO(db);
  }

  /**
   * 处理作品消息
   */
  async handleWorkMessage(data) {
    const { account_id, data: work } = data;

    logger.info(`Received work for account ${account_id}:`, work.platform_work_id);

    try {
      // 检查是否已存在
      const existing = await this.worksDAO.findByPlatformWorkId(
        account_id,
        work.platform,
        work.platform_work_id
      );

      if (existing) {
        // 更新统计数据
        await this.worksDAO.update(existing.id, {
          total_comment_count: work.total_comment_count,
          like_count: work.like_count,
          share_count: work.share_count,
          view_count: work.view_count,
          last_crawl_time: work.last_crawl_time,
          updated_at: Math.floor(Date.now() / 1000),
        });
      } else {
        // 插入新作品
        await this.worksDAO.insert(work);
      }
    } catch (error) {
      logger.error('Failed to handle work message:', error);
    }
  }

  /**
   * 处理讨论消息
   */
  async handleDiscussionMessage(data) {
    const { account_id, data: discussion } = data;

    logger.info(`Received discussion for account ${account_id}:`, discussion.platform_discussion_id);

    try {
      // 检查是否已存在
      const existing = await this.discussionsDAO.findByPlatformDiscussionId(
        account_id,
        discussion.platform_user_id,
        discussion.platform_discussion_id
      );

      if (!existing) {
        await this.discussionsDAO.insert(discussion);

        // 发送通知
        await this.notifyNewDiscussion(discussion);
      }
    } catch (error) {
      logger.error('Failed to handle discussion message:', error);
    }
  }

  /**
   * 注册新的消息处理器
   */
  registerHandlers() {
    // 现有处理器...

    // ✨ 新增
    this.socket.on('worker:work_detected', (data) => {
      this.handleWorkMessage(data);
    });

    this.socket.on('worker:discussion_detected', (data) => {
      this.handleDiscussionMessage(data);
    });

    this.socket.on('worker:bulk_insert_works', async (data) => {
      const { account_id, works } = data;
      await this.worksDAO.bulkInsert(works);
      logger.info(`Bulk inserted ${works.length} works for account ${account_id}`);
    });
  }
}
```

---

#### 📋 任务 7: 协议消息类型扩展
**文件**: `packages/shared/protocol/messages.js`

**新增消息类型**:
```javascript
// Worker → Master 消息
const WORKER_WORK_DETECTED = 'worker:work_detected';
const WORKER_DISCUSSION_DETECTED = 'worker:discussion_detected';
const WORKER_BULK_INSERT_WORKS = 'worker:bulk_insert_works';
const WORKER_BULK_INSERT_DISCUSSIONS = 'worker:bulk_insert_discussions';

// Master → Worker 消息
const MASTER_CRAWL_WORKS = 'master:crawl_works';
const MASTER_CRAWL_DISCUSSIONS = 'master:crawl_discussions';

module.exports = {
  // 现有消息类型...

  // ✨ 新增
  WORKER_WORK_DETECTED,
  WORKER_DISCUSSION_DETECTED,
  WORKER_BULK_INSERT_WORKS,
  WORKER_BULK_INSERT_DISCUSSIONS,
  MASTER_CRAWL_WORKS,
  MASTER_CRAWL_DISCUSSIONS,
};
```

---

#### 📋 任务 8: 迁移 `douyin_videos` 到 `works`
**文件**: `packages/master/src/database/migrations/migrate-videos-to-works.js`

**迁移脚本**:
```javascript
/**
 * 将 douyin_videos 表数据迁移到 works 表
 */
async function migrateDouyinVideosToWorks(db) {
  const douyinVideoDAO = new DouyinVideoDAO(db);
  const worksDAO = new WorksDAO(db);

  logger.info('Starting migration: douyin_videos → works');

  // 1. 获取所有 douyin_videos 数据
  const videos = await db.all('SELECT * FROM douyin_videos');

  logger.info(`Found ${videos.length} videos to migrate`);

  // 2. 转换为 works 格式
  const works = videos.map(video => ({
    id: video.id,
    account_id: video.account_id,
    platform: 'douyin',
    platform_work_id: video.platform_videos_id,
    platform_user_id: video.platform_user_id,
    work_type: 'video', // 所有 douyin_videos 都是视频
    title: video.title,
    description: null,
    cover: video.cover,
    url: null,
    publish_time: video.publish_time ? new Date(video.publish_time).getTime() / 1000 : null,
    total_comment_count: video.total_comment_count || 0,
    new_comment_count: video.new_comment_count || 0,
    like_count: video.like_count || 0,
    share_count: video.share_count || 0,
    view_count: video.play_count || 0,
    last_crawl_time: video.last_crawl_time,
    crawl_status: video.crawl_status || 'pending',
    crawl_error: video.crawl_error,
    is_new: video.is_new || false,
    push_count: video.push_count || 0,
    created_at: video.created_at,
    updated_at: video.updated_at,
  }));

  // 3. 批量插入到 works 表
  await worksDAO.bulkInsert(works);

  logger.info(`✅ Migration completed: ${works.length} works inserted`);

  // 4. (可选) 备份并删除旧表
  // await db.run('CREATE TABLE douyin_videos_backup AS SELECT * FROM douyin_videos');
  // await db.run('DROP TABLE douyin_videos');
}
```

---

### 3.2 次要开发任务 (中优先级)

#### 📋 任务 9: 扩展评论爬虫支持新字段
**文件**: `packages/worker/src/platforms/douyin/crawl-comments.js`

**新增字段提取**:
```javascript
// 现有实现
const comment = {
  platform_comment_id: fiber.cid,
  content: fiber.text,
  author_name: fiber.user.nickname,
  author_id: fiber.user.uid,
  // ✨ 新增
  author_avatar: fiber.user.avatar_url,
  like_count: fiber.digg_count,
  reply_count: fiber.reply_comment_total,
};
```

---

#### 📋 任务 10: 扩展私信爬虫支持新字段
**文件**: `packages/worker/src/platforms/douyin/crawl-direct-messages-v2.js`

**新增字段提取**:
```javascript
const message = {
  // 现有字段...

  // ✨ 新增
  sender_name: props.senderName,
  status: props.status || 'sent',
  reply_to_message_id: props.reply_to,

  // 媒体字段
  media_url: props.content?.url,
  media_thumbnail: props.content?.thumbnail,
  file_size: props.content?.file_size,
  file_name: props.content?.file_name,
  duration: props.content?.duration,

  // 删除/撤回
  is_deleted: props.is_deleted || false,
  is_recalled: props.is_recalled || false,
  recalled_at: props.recalled_at,
};
```

---

#### 📋 任务 11: 会话表支持新字段
**文件**: `packages/worker/src/platforms/douyin/crawl-direct-messages-v2.js`

**扩展会话提取**:
```javascript
const conversation = {
  // 现有字段...

  // ✨ 新增
  is_pinned: apiData.is_pinned || false,
  is_muted: apiData.is_muted || false,
  last_message_type: detectMessageType(apiData.last_message),
  status: apiData.status || 'active',
};
```

---

## 四、开发优先级建议

### 🔴 P0 - 核心基础 (必须优先完成)
1. ✅ **任务 1**: 实现 `WorksDAO` (1-2 天)
2. ✅ **任务 2**: 实现 `DiscussionsDAO` (1-2 天)
3. ✅ **任务 7**: 协议消息类型扩展 (0.5 天)

### 🟠 P1 - 核心功能 (高优先级)
4. ✅ **任务 3**: Worker 实现作品爬虫 (3-5 天)
5. ✅ **任务 5**: Worker 消息上报器扩展 (1 天)
6. ✅ **任务 6**: Master 消息接收器扩展 (1 天)

### 🟡 P2 - 扩展功能 (中优先级)
7. ✅ **任务 4**: Worker 实现讨论爬虫 (2-3 天)
8. ✅ **任务 9**: 扩展评论爬虫支持新字段 (1 天)
9. ✅ **任务 10**: 扩展私信爬虫支持新字段 (1 天)
10. ✅ **任务 11**: 会话表支持新字段 (0.5 天)

### 🟢 P3 - 数据迁移 (低优先级)
11. ✅ **任务 8**: 迁移 `douyin_videos` 到 `works` (1-2 天)

---

## 五、技术难点预估

### 5.1 作品爬虫挑战
- **虚拟列表滚动**: 作品列表通常是虚拟滚动，需要类似私信爬虫的分页加载逻辑
- **作品类型检测**: 抖音支持视频/图文/合集等多种类型，需要准确识别
- **API 拦截**: 可能需要拦截 `/aweme/v1/web/aweme/post/` 等 API 获取完整数据

### 5.2 讨论爬虫挑战
- **嵌套层级**: 评论可能有多级嵌套 (评论 → 回复 → 回复的回复)
- **展开交互**: 需要模拟点击"查看更多回复"按钮
- **性能问题**: 每个评论展开回复会增加页面操作次数，需要优化

### 5.3 数据一致性
- **外键关系**: `discussions` 表依赖 `comments` 和 `works` 表，需要确保数据插入顺序
- **重复检测**: 使用唯一约束 `(account_id, platform_user_id, platform_discussion_id)` 去重

---

## 六、测试验证计划

### 6.1 DAO 单元测试
**文件**: `tests/works-dao.test.js`, `tests/discussions-dao.test.js`

```javascript
describe('WorksDAO', () => {
  test('should insert work', async () => {
    const work = { /* ... */ };
    const id = await worksDAO.insert(work);
    expect(id).toBeDefined();
  });

  test('should enforce unique constraint', async () => {
    const work = { account_id: 'acc1', platform: 'douyin', platform_work_id: 'w1' };
    await worksDAO.insert(work);

    await expect(worksDAO.insert(work)).rejects.toThrow('UNIQUE constraint');
  });

  // ... 更多测试
});
```

### 6.2 集成测试
**文件**: `tests/crawler-integration.test.js`

```javascript
describe('Works Crawler Integration', () => {
  test('should crawl works and save to database', async () => {
    const account = { id: 'acc1', platform_user_id: 'u1' };

    // 1. 爬取作品
    const works = await crawlWorks(page, account);

    // 2. 上报到 Master
    messageReporter.reportWorks(account.id, works);

    // 3. 验证数据库
    const saved = await worksDAO.findByAccount(account.id);
    expect(saved.length).toBeGreaterThan(0);
  });
});
```

---

## 七、总结

### 当前状态
- ✅ **已完成**: `conversations`, `direct_messages`, `comments` 的爬虫和存储
- ⚠️ **部分完成**: `douyin_videos` (需迁移到 `works`)
- ❌ **未开始**: `works`, `discussions` 的爬虫和存储

### 需要开发的核心组件
1. **2 个 DAO 类**: `WorksDAO`, `DiscussionsDAO`
2. **2 个爬虫脚本**: `crawl-works.js`, `crawl-discussions.js`
3. **消息上报扩展**: `message-reporter.js`
4. **消息接收扩展**: `message-receiver.js`
5. **协议扩展**: `messages.js` 新增消息类型
6. **数据迁移**: `douyin_videos` → `works`

### 预估工作量
- **总工时**: 15-20 天 (1 个开发人员全职)
- **关键路径**: DAO → 协议 → 爬虫 → 上报 → 接收 → 测试

### 建议实施顺序
1. Week 1: 完成 P0 和 P1 任务 (DAO + 基础对接)
2. Week 2: 完成 P2 任务 (作品爬虫)
3. Week 3: 完成 P2-P3 任务 (讨论爬虫 + 字段扩展 + 迁移)
4. Week 4: 测试和优化

---

**文档版本**: 1.0
**最后更新**: 2025-10-24
**维护者**: Claude Code
