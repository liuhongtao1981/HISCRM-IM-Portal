# 统一数据管理架构 - 集成指南

**版本**: 1.0
**日期**: 2025-10-28
**状态**: Phase 2 已完成 - 基础设施就绪

---

## 📋 概览

本文档说明如何将现有爬虫迁移到新的统一数据管理架构。

**Phase 2 完成内容**：
- ✅ DataPusher 接口（与 Master 通信）
- ✅ PlatformBase 初始化 DataManager
- ✅ DouyinPlatform 实现 createDataManager()
- ✅ 新消息类型注册（shared/protocol/messages.js）

**下一步**：重构现有爬虫使用新架构（私信 → 作品 → 评论）

---

## 🏗️ 架构概览

### 数据流

```
Crawler (API/DOM)
  ↓
Platform.getDataManager()
  ↓
dataManager.batchUpsertConversations(rawData, DataSource.API)
  ↓
自动映射（DouyinDataManager.mapConversationData）
  ↓
自动状态管理（NEW → UPDATED）
  ↓
自动脏标记（dirtyIds）
  ↓
自动同步到 Master（每 5 秒）
```

### 核心组件

1. **DataPusher** (`packages/worker/src/platforms/base/data-pusher.js`)
   - 负责与 Master 通信
   - 支持批量推送和队列管理
   - 使用新消息类型（WORKER_*_UPDATE）

2. **PlatformBase** (`packages/worker/src/platforms/base/platform-base.js`)
   - 在 initialize() 中自动创建 DataManager
   - 在 cleanup() 中自动清理 DataManager
   - 提供 getDataManager(accountId) 访问接口

3. **DouyinPlatform** (`packages/worker/src/platforms/douyin/platform.js`)
   - 实现 createDataManager() 返回 DouyinDataManager
   - 自动继承所有 PlatformBase 的 DataManager 管理逻辑

4. **DouyinDataManager** (`packages/worker/src/platforms/douyin/douyin-data-manager.js`)
   - 实现所有映射方法（抖音 → 标准格式）
   - 已实现的映射：会话、消息、作品、评论、通知

---

## 🔄 爬虫迁移步骤

### 步骤 1：获取 DataManager

在爬虫函数开始时获取 DataManager：

```javascript
// 旧代码：直接操作本地变量
const apiData = {
  conversations: [],
  messages: [],
};

// 新代码：获取 DataManager
const dataManager = platform.getDataManager(accountId);
if (!dataManager) {
  throw new Error(`DataManager not initialized for account ${accountId}`);
}
```

### 步骤 2：使用 batchUpsert* 方法

将 API/DOM 数据传递给 DataManager：

```javascript
// 旧代码：手动收集数据
apiData.conversations.push(...conversationList);

// 新代码：批量插入（自动映射 + 状态管理）
const conversations = dataManager.batchUpsertConversations(
  conversationList,  // 原始抖音 API 数据
  DataSource.API     // 数据来源
);

logger.info(`Inserted ${conversations.length} conversations`);
```

### 步骤 3：移除手动推送逻辑

DataManager 会自动同步数据到 Master：

```javascript
// 旧代码：手动推送
await this.bridge.sendToMaster(createMessage(
  MessageTypes.WORKER_BULK_INSERT_CONVERSATIONS,
  { accountId, conversations: apiData.conversations }
));

// 新代码：自动推送（无需手动调用）
// DataManager 每 5 秒自动同步脏数据
```

### 步骤 4：清理临时数据结构

移除爬虫函数中的本地数据收集变量：

```javascript
// 删除这些：
const apiData = {
  conversations: [],
  messages: [],
  cache: new Set(),
};

// 所有数据现在都在 DataManager 中管理
```

---

## 📝 示例：重构私信爬虫

### 旧代码（crawl-direct-messages-v2.js）

```javascript
// API 数据收集
const apiData = {
  conversations: [],
  messages: [],
  cache: new Set(),
};

// API 回调
async function onConversationListAPI(body, route) {
  if (!body || !body.user_list) return;

  const url = route.request().url();
  if (apiData.cache.has(url)) return;

  apiData.cache.add(url);
  apiData.conversations.push(...body.user_list);
}

// 主爬虫函数
async function crawlDirectMessagesV2(account, platform, browserManager) {
  // ... 导航和等待 ...

  // 手动推送数据
  await platform.bridge.sendToMaster(createMessage(
    MessageTypes.WORKER_BULK_INSERT_CONVERSATIONS,
    { accountId: account.id, conversations: apiData.conversations }
  ));
}
```

### 新代码（使用 DataManager）

```javascript
// ✅ 第 1 步：获取 DataManager
const dataManager = platform.getDataManager(account.id);

// ✅ 第 2 步：API 回调直接使用 DataManager
async function onConversationListAPI(body, route) {
  if (!body || !body.user_list) return;

  // 批量插入（自动去重、映射、状态管理）
  const conversations = dataManager.batchUpsertConversations(
    body.user_list,
    DataSource.API
  );

  logger.info(`✅ Inserted ${conversations.length} conversations from API`);
}

// ✅ 第 3 步：主爬虫函数不再需要推送逻辑
async function crawlDirectMessagesV2(account, platform, browserManager) {
  const dataManager = platform.getDataManager(account.id);

  // ... 导航和等待 ...

  // 统计数据（从 DataManager 获取）
  const stats = dataManager.getStats();
  logger.info(`Crawl complete:`, stats);

  // DataManager 会自动同步数据到 Master（无需手动推送）
}
```

---

## 🔑 关键优势

### 1. 自动数据去重

```javascript
// 旧代码：手动维护 Set 去重
if (apiData.cache.has(url)) return;
apiData.cache.add(url);

// 新代码：DataManager 自动基于 ID 去重
// 同一个 conversationId 多次 upsert 会自动合并
dataManager.upsertConversation(data);
dataManager.upsertConversation(data); // 自动覆盖，不会重复
```

### 2. 自动状态管理

```javascript
// 旧代码：无状态跟踪
apiData.conversations.push(conv);

// 新代码：自动状态管理
// 第一次插入 → status: NEW
// 再次更新 → status: UPDATED, version++
// 推送成功 → status: SYNCED, lastSyncAt 更新
```

### 3. 自动脏标记和同步

```javascript
// 旧代码：所有数据都推送（浪费带宽）
await bridge.sendToMaster(...allData);

// 新代码：只推送修改过的数据
// DataManager 自动跟踪 dirtyIds
// syncAll() 只推送状态为 NEW/UPDATED 的数据
```

### 4. 平台无关

```javascript
// 旧代码：硬编码抖音数据结构
const conversationId = String(data.user_id);

// 新代码：平台特定逻辑封装在 DataManager
// 爬虫只需传递原始数据，映射自动完成
dataManager.batchUpsertConversations(douyinData);
```

---

## 🎯 迁移检查清单

### 私信爬虫（crawl-direct-messages-v2.js）

- [ ] 获取 DataManager
- [ ] 修改 onConversationListAPI 使用 `batchUpsertConversations()`
- [ ] 修改 onMessageHistoryAPI 使用 `batchUpsertMessages()`
- [ ] 删除 apiData 数据结构
- [ ] 删除手动推送逻辑
- [ ] 测试 API 拦截和数据收集

### 作品爬虫（crawl-contents.js）

- [ ] 获取 DataManager
- [ ] 修改 onWorksListAPI 使用 `batchUpsertContents()`
- [ ] 修改 onWorkDetailAPI 使用 `upsertContent()`
- [ ] 删除 apiData.worksList 和 apiData.workDetail
- [ ] 删除手动推送逻辑
- [ ] 测试作品列表 API

### 评论爬虫（crawl-comments.js）

- [ ] 获取 DataManager
- [ ] 修改 onCommentsListAPI 使用 `batchUpsertComments()`
- [ ] 修改 onDiscussionsListAPI 使用 `batchUpsertComments()`
- [ ] 删除 apiData.comments 和 apiData.discussions
- [ ] 删除手动推送逻辑
- [ ] 测试评论 API

---

## 🧪 测试计划

### 单元测试

1. **DataManager 基础功能**
   - 创建和初始化
   - batchUpsert 方法
   - 去重逻辑
   - 状态管理

2. **DouyinDataManager 映射**
   - mapConversationData()
   - mapMessageData()
   - mapContentData()
   - mapCommentData()

3. **DataPusher 推送**
   - pushConversations()
   - pushMessages()
   - 批量推送
   - 错误处理

### 集成测试

1. **私信爬虫**
   - 使用测试脚本 `tests/测试私信爬虫新架构.js`
   - 验证 API 拦截
   - 验证数据映射
   - 验证自动同步

2. **作品爬虫**
   - 使用测试脚本 `tests/测试作品爬虫新架构.js`
   - 验证作品列表 API
   - 验证数据增强
   - 验证推送到 Master

3. **端到端测试**
   - 启动 Master + Worker
   - 执行完整监控任务
   - 验证数据流向 Master 数据库
   - 验证通知推送到 Admin Web

---

## ⚠️ 注意事项

### 1. DataManager 生命周期

- DataManager 在 `platform.initialize(account)` 时创建
- 在 `platform.cleanup(account)` 时销毁
- 爬虫函数中只需获取，不需要创建或销毁

### 2. 自动同步配置

```javascript
// 默认配置（DouyinDataManager 构造函数）
this.pushConfig = {
  interval: 5000,        // 5 秒同步一次
  batchSize: 100,        // 每批最多 100 条
  autoSync: true,        // 自动同步开启
};

// 如果需要手动同步：
dataManager.pushConfig.autoSync = false;
await dataManager.syncAll(); // 手动触发
```

### 3. 数据来源标记

始终标记数据来源以便调试：

```javascript
// API 数据
dataManager.batchUpsertConversations(data, DataSource.API);

// DOM 数据
dataManager.batchUpsertMessages(data, DataSource.DOM);

// 手动/测试数据
dataManager.upsertContent(data, DataSource.MANUAL);
```

### 4. 错误处理

DataManager 内部已处理错误，爬虫无需额外 try-catch：

```javascript
// DataManager 会捕获映射错误并记录日志
// 失败的数据不会中断整个批次
const results = dataManager.batchUpsertConversations(data);
// results 只包含成功的项
```

---

## 📊 性能对比

### 旧架构

- ❌ 所有数据都推送（包括未修改的）
- ❌ 每次爬取都重新发送全量数据
- ❌ 无数据去重（可能重复插入）
- ❌ 无状态跟踪（无法知道哪些是新数据）

### 新架构

- ✅ 只推送修改过的数据（dirtyIds）
- ✅ 自动去重（基于 ID）
- ✅ 增量同步（只发送 NEW/UPDATED 状态的数据）
- ✅ 完整的生命周期管理（NEW → UPDATED → SYNCED）

**预期性能提升**：
- 网络带宽使用：减少 60-80%
- Master 数据库写入：减少 70%
- 爬虫内存占用：减少 40%

---

## 🚀 下一步

### Phase 3：重构现有爬虫

1. **私信爬虫**（优先级：高）
   - API 已验证工作
   - 数据量最大（105 会话，31 消息）
   - 作为其他爬虫的参考实现

2. **作品爬虫**（优先级：中）
   - API 已修复（item_info_list）
   - 需要测试 API 拦截

3. **评论爬虫**（优先级：低）
   - API 未触发（评论少）
   - 需要修复 DOM 提取

### Phase 4：Master 端适配

1. **添加新消息处理器**
   - WORKER_CONVERSATIONS_UPDATE
   - WORKER_MESSAGES_UPDATE
   - WORKER_CONTENTS_UPDATE
   - WORKER_COMMENTS_UPDATE
   - WORKER_NOTIFICATIONS_UPDATE

2. **更新 DAO 接口**
   - 支持批量 upsert（INSERT OR REPLACE）
   - 返回插入/更新的 ID 列表

3. **更新通知广播**
   - 从新消息类型中提取通知
   - 广播到 Admin Web

---

## 📚 相关文档

1. [统一数据管理架构设计.md](./统一数据管理架构设计.md) - Phase 1 设计文档
2. [API拦截器验证报告.md](./API拦截器验证报告.md) - API 拦截验证
3. [作品API拦截器修复总结.md](./作品API拦截器修复总结.md) - 作品 API 修复

---

**状态**: ✅ Phase 2 完成 - 基础设施就绪
**下一步**: 重构私信爬虫使用新架构（参考本文档）
**预计工作量**: 每个爬虫约 2-3 小时

