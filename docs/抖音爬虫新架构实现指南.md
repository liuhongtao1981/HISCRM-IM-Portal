# 抖音爬虫新架构实现指南

**版本**: v2.0
**创建日期**: 2025-10-27
**状态**: 🚧 实施中

---

## 📋 架构概览

### 核心设计理念

**关注点分离**: API 拦截与 DOM 操作完全解耦

```
┌────────────────────────────────────────────────────┐
│  全局 API 拦截器 (GlobalAPIInterceptor)             │
│  - 统一拦截所有 API 响应                             │
│  - 自动匹配规则并存储数据                            │
│  - 提供统一查询接口                                  │
└────────────────────────────────────────────────────┘
                       ↓ 数据流
┌────────────────────────────────────────────────────┐
│  爬虫任务 (Crawlers)                                │
│  - 只负责 DOM/虚表操作                              │
│  - 从拦截器获取 API 数据                            │
│  - 合并数据并返回                                   │
└────────────────────────────────────────────────────┘
```

---

## 🏗️ 模块结构

### 文件组织

```
packages/worker/src/platforms/douyin/
├── _backup_20251027/              # 旧代码备份
│   ├── platform.js
│   ├── crawl-works.js
│   ├── crawl-comments.js
│   └── crawl-direct-messages-v2.js
│
├── global-api-interceptor.js      # ✨ 新增: 全局拦截器
├── platform.js                    # 🔧 修改: 集成拦截器
│
├── crawlers/                      # ✨ 新增: 爬虫目录
│   ├── crawl-works.js             # 🆕 重写: 作品爬虫
│   ├── crawl-comments.js          # 🆕 重写: 评论爬虫
│   └── crawl-messages.js          # 🆕 重写: 私信爬虫
│
└── utils/                         # ✨ 新增: 工具函数
    ├── data-merger.js             # 数据合并工具
    ├── time-parser.js             # 时间解析工具
    └── virtual-list-scroller.js   # 虚拟列表滚动工具
```

---

## 📝 实现步骤

### 步骤 1: 全局拦截器 ✅

**文件**: `global-api-interceptor.js`

**功能**:
- ✅ 规则注册机制
- ✅ 响应监听和处理
- ✅ 数据存储和查询
- ✅ 自动去重

**使用示例**:
```javascript
const globalAPIInterceptor = require('./global-api-interceptor');

// 在 Platform 初始化时
await globalAPIInterceptor.init(browserContext);

// 在爬虫中获取数据
const data = globalAPIInterceptor.getInterceptedData('works');

// 清空缓存
globalAPIInterceptor.clearData('works');
```

---

### 步骤 2: 修改 Platform 集成拦截器

**任务**: 修改 `platform.js` 以集成全局拦截器

**实现要点**:

#### 2.1 在 login() 中初始化拦截器

```javascript
const globalAPIInterceptor = require('./global-api-interceptor');

class DouyinPlatform extends PlatformBase {
  async login(accountId) {
    // ... 现有登录逻辑 ...

    // 🆕 初始化全局拦截器
    const context = this.browserManager.getContext(accountId);
    if (context && !globalAPIInterceptor.isReady()) {
      await globalAPIInterceptor.init(context);
      logger.info('✅ Global API Interceptor initialized');
    }

    return { success: true };
  }
}
```

#### 2.2 在 startMonitoring() 中确保拦截器就绪

```javascript
async startMonitoring(accountId) {
  // 确保拦截器已初始化
  const context = this.browserManager.getContext(accountId);
  if (context && !globalAPIInterceptor.isReady()) {
    await globalAPIInterceptor.init(context);
  }

  // ... 现有监控逻辑 ...
}
```

---

### 步骤 3: 实现作品爬虫

**文件**: `crawlers/crawl-works.js`

**功能**:
- 导航到作品管理页
- 滚动虚拟列表加载所有作品 (DOM)
- 从全局拦截器获取 API 数据
- 合并数据并返回

**代码结构**:

```javascript
const globalAPIInterceptor = require('../global-api-interceptor');
const { createLogger } = require('@hiscrm-im/shared/utils/logger');
const { v4: uuidv4 } = require('uuid');

const logger = createLogger('crawl-works');

/**
 * 爬取作品列表
 * @param {Page} page - Playwright Page 实例
 * @param {Object} account - 账户信息
 * @param {Object} options - 配置选项
 * @returns {Promise<Object>} { works, stats }
 */
async function crawlWorks(page, account, options = {}) {
  const { maxWorks = 100 } = options;

  logger.info(`Starting works crawl for account ${account.id}`);

  try {
    // 步骤 1: 清空之前的数据
    globalAPIInterceptor.clearData('works');

    // 步骤 2: 导航到作品页
    await page.goto('https://creator.douyin.com/creator-micro/content/manage', {
      waitUntil: 'networkidle',
      timeout: 30000
    });
    await page.waitForTimeout(2000);

    // 步骤 3: 滚动加载所有作品 (DOM 操作)
    const domWorks = await loadAllWorksFromDOM(page, maxWorks);
    logger.info(`Loaded ${domWorks.length} works from DOM`);

    // 步骤 4: 获取 API 拦截数据
    const apiData = globalAPIInterceptor.getInterceptedData('works');
    logger.info(`Intercepted ${apiData.length} API responses`);

    // 步骤 5: 合并数据
    const mergedWorks = mergeWorksData(domWorks, apiData, account);
    logger.info(`Merged ${mergedWorks.length} works`);

    return {
      works: mergedWorks,
      stats: {
        totalWorks: mergedWorks.length,
        domWorks: domWorks.length,
        apiResponses: apiData.length
      }
    };

  } catch (error) {
    logger.error('Error in crawlWorks:', error);
    throw error;
  }
}

/**
 * 从 DOM 加载作品列表 (虚拟列表滚动)
 */
async function loadAllWorksFromDOM(page, maxWorks) {
  // TODO: 实现虚拟列表滚动逻辑
  // 1. 查找作品列表容器
  // 2. 循环滚动直到收敛
  // 3. 从 React Fiber 提取作品 ID 和基础信息
  return [];
}

/**
 * 合并 DOM 数据和 API 数据
 */
function mergeWorksData(domWorks, apiData, account) {
  // TODO: 实现数据合并逻辑
  // 1. 创建 API 数据 Map (按 item_id_plain 索引)
  // 2. 遍历 DOM 作品,查找对应的 API 数据
  // 3. 合并并标准化字段
  return [];
}

module.exports = {
  crawlWorks
};
```

**实现提示**:

1. **虚拟列表滚动**:
   - 查找容器: `document.querySelector('[class*="content-list"]')`
   - 滚动逻辑: `container.scrollTop = container.scrollHeight`
   - 收敛检测: 连续 3 次作品数量不变

2. **React Fiber 提取**:
   - 查找 Fiber 键: `Object.keys(element).find(key => key.startsWith('__react'))`
   - 提取作品 ID: `fiber.memoizedProps.item_id_plain`

3. **数据合并**:
   - API 数据优先级高于 DOM 数据
   - 使用 `item_id_plain` 作为匹配键
   - 解析时间: `parseCreatorAPITime(apiData.create_time)`

---

### 步骤 4: 实现评论爬虫

**文件**: `crawlers/crawl-comments.js`

**功能**:
- 导航到评论管理页
- 点击视频触发 API 请求
- 从全局拦截器获取评论和讨论数据
- 合并并返回

**代码结构**:

```javascript
const globalAPIInterceptor = require('../global-api-interceptor');

async function crawlComments(page, account, options = {}) {
  try {
    // 步骤 1: 清空数据
    globalAPIInterceptor.clearData('comments');
    globalAPIInterceptor.clearData('discussions');

    // 步骤 2: 导航到评论页
    await page.goto('https://creator.douyin.com/creator-micro/data/comment');

    // 步骤 3: 获取视频列表 (DOM)
    const videos = await getVideoList(page);

    // 步骤 4: 点击视频触发 API
    for (const video of videos) {
      await clickVideo(page, video);
      await page.waitForTimeout(1000);
    }

    // 步骤 5: 获取拦截数据
    const commentsData = globalAPIInterceptor.getInterceptedData('comments');
    const discussionsData = globalAPIInterceptor.getInterceptedData('discussions');

    // 步骤 6: 解析并返回
    const comments = parseComments(commentsData, account);
    const discussions = parseDiscussions(discussionsData, account);

    return { comments, discussions, stats: {...} };

  } catch (error) {
    logger.error('Error in crawlComments:', error);
    throw error;
  }
}

module.exports = { crawlComments };
```

---

### 步骤 5: 实现私信爬虫

**文件**: `crawlers/crawl-messages.js`

**功能**:
- 导航到私信页
- 提取会话列表 (DOM + API)
- 点击每个会话,滚动消息历史
- 从全局拦截器获取消息数据

**代码结构**:

```javascript
const globalAPIInterceptor = require('../global-api-interceptor');

async function crawlMessages(page, account, options = {}) {
  try {
    // 步骤 1: 清空数据
    globalAPIInterceptor.clearData('conversations');
    globalAPIInterceptor.clearData('messages');

    // 步骤 2: 导航到私信页
    await page.goto('https://creator.douyin.com/creator-micro/data/following/chat');

    // 步骤 3: 获取会话列表
    const conversations = await extractConversations(page, account);

    // 步骤 4: 遍历会话,获取消息
    const allMessages = [];
    for (const conv of conversations) {
      await openConversation(page, conv);
      await scrollMessageHistory(page);
      await returnToList(page);
    }

    // 步骤 5: 获取拦截数据
    const messagesData = globalAPIInterceptor.getInterceptedData('messages');

    // 步骤 6: 解析并返回
    const messages = parseMessages(messagesData, conversations, account);

    return { conversations, messages, stats: {...} };

  } catch (error) {
    logger.error('Error in crawlMessages:', error);
    throw error;
  }
}

module.exports = { crawlMessages };
```

---

## 🔧 工具函数

### data-merger.js - 数据合并工具

```javascript
/**
 * 合并 DOM 数据和 API 数据
 * @param {Array} domData - DOM 提取的数据
 * @param {Array} apiData - API 拦截的数据
 * @param {string} idKey - 匹配键名
 * @returns {Array} 合并后的数据
 */
function mergeData(domData, apiData, idKey = 'id') {
  // 创建 API 数据 Map
  const apiMap = new Map();
  apiData.forEach(response => {
    response.data.items?.forEach(item => {
      const id = item[idKey];
      if (id) apiMap.set(String(id), item);
    });
  });

  // 合并数据
  return domData.map(dom => {
    const api = apiMap.get(String(dom[idKey]));
    return api ? { ...dom, ...api, source: 'api_enhanced' } : dom;
  });
}

module.exports = { mergeData };
```

### time-parser.js - 时间解析工具

```javascript
/**
 * 解析创作者中心 API 的时间格式
 * @param {string|number} timeValue - "2025-10-22 16:37" 或时间戳
 * @returns {number|null} Unix 时间戳 (秒)
 */
function parseCreatorAPITime(timeValue) {
  if (!timeValue) return null;

  // 如果是数字,直接返回
  if (typeof timeValue === 'number') {
    return timeValue > 9999999999 ? Math.floor(timeValue / 1000) : timeValue;
  }

  // 如果是字符串,解析为 Date
  try {
    const date = new Date(timeValue);
    return Math.floor(date.getTime() / 1000);
  } catch {
    return null;
  }
}

module.exports = { parseCreatorAPITime };
```

---

## 📊 数据流程图

### 作品爬虫数据流

```
┌──────────────┐
│ 1. 清空缓存  │  globalAPIInterceptor.clearData('works')
└──────┬───────┘
       │
       ▼
┌──────────────┐
│ 2. 导航页面  │  page.goto(...)
└──────┬───────┘
       │
       ▼
┌──────────────┐
│ 3. 滚动列表  │  loadAllWorksFromDOM()
│   (DOM操作)  │  → 触发 API 请求
└──────┬───────┘  → 拦截器自动捕获
       │
       ▼
┌──────────────┐
│ 4. 获取API   │  globalAPIInterceptor.getInterceptedData('works')
│   拦截数据   │  → [ {data: {items: [...]}, ...} ]
└──────┬───────┘
       │
       ▼
┌──────────────┐
│ 5. 合并数据  │  mergeWorksData(domWorks, apiData)
│   DOM + API  │  → 标准化字段
└──────┬───────┘
       │
       ▼
┌──────────────┐
│ 6. 返回结果  │  { works, stats }
└──────────────┘
```

---

## ✅ 验证清单

### 全局拦截器验证

- [ ] 拦截器在 Platform 初始化时成功注册
- [ ] 5 个默认规则全部注册
- [ ] 响应监听器正常工作
- [ ] 去重机制有效
- [ ] 统计信息正确

### 作品爬虫验证

- [ ] 能正常导航到作品页
- [ ] 虚拟列表滚动正常
- [ ] DOM 提取作品 ID 正确
- [ ] API 拦截成功 (source = 'api_enhanced')
- [ ] 数据合并正确 (title, cover, publish_time 等字段完整)

### 评论爬虫验证

- [ ] 能正常点击视频
- [ ] 评论 API 拦截成功
- [ ] 讨论 API 拦截成功
- [ ] is_author, level 字段正确
- [ ] reply_to_user_info 字段完整

### 私信爬虫验证

- [ ] 会话列表提取正确
- [ ] 消息历史拦截成功
- [ ] conversation_id 匹配正确
- [ ] 消息方向 (incoming/outgoing) 正确

---

## 🐛 调试技巧

### 1. 查看拦截统计

```javascript
const stats = globalAPIInterceptor.getStats();
console.log('Interceptor Stats:', stats);
// Output:
// {
//   total: 25,
//   byType: { works: 5, comments: 12, discussions: 8 },
//   cacheSize: 25,
//   dataSize: { works: 5, comments: 12, ... }
// }
```

### 2. 导出拦截数据

```javascript
const fs = require('fs');
const data = globalAPIInterceptor.getInterceptedData('works');
fs.writeFileSync('./debug-works-api.json', JSON.stringify(data, null, 2));
```

### 3. 启用详细日志

```javascript
// 在 global-api-interceptor.js 中临时修改日志级别
logger.setLevel('debug');
```

---

## 📚 下一步

1. **修改 platform.js** - 集成全局拦截器
2. **实现 crawl-works.js** - 作品爬虫
3. **实现 crawl-comments.js** - 评论爬虫
4. **实现 crawl-messages.js** - 私信爬虫
5. **端到端测试** - 完整爬取周期验证
6. **性能优化** - 内存和速度优化
7. **文档完善** - API 文档和使用示例

---

**文档维护**: Claude Code
**实施状态**: 步骤 1 已完成 ✅,步骤 2-5 待实施
